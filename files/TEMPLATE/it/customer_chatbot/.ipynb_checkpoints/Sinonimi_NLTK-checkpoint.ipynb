{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package omw is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'caratteri'}\n"
     ]
    }
   ],
   "source": [
    "sinonimi = set()\n",
    "nome = \"caratteri\"\n",
    "sinonimi.add(nome)\n",
    "it_lemmas = wn.lemmas(nome.lower(), lang=\"ita\")\n",
    "for i in range(len(it_lemmas)):\n",
    "    hypernyms = it_lemmas[i].synset().hypernyms()\n",
    "    for i in range(len(hypernyms)):\n",
    "        syn = hypernyms[i].lemmas(lang=\"ita\")\n",
    "        print(syn)\n",
    "        for s in syn:\n",
    "            sinonimi.add(str(s).split(\".\")[3].replace(\"')\", \"\"))\n",
    "\n",
    "print(sinonimi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESEMPIO\n",
    "# Per ogni nlp delle frasi in faq_questions, se un token è root o entita,\n",
    "# si cercano i sinonimi e si aggiungono alla tabella synonyms (se ce ne sono)\n",
    "\n",
    "file_connessione = open(\"../../db_connections/DB_CONNECTIONS.json\", \"r\")\n",
    "dati_connessione = str(file_connessione.read().replace(':', '=').replace('username', 'user').replace('password=', 'passwd=').replace('database', 'db')[1:-1])\n",
    "conn = eval(\"MySQLdb.connect(\" + dati_connessione + \")\")\n",
    "file_connessione.close()\n",
    "cursor = conn.cursor()\n",
    "\n",
    "nlp = spacy.load(\"../model/model_NER/model\")\n",
    "\n",
    "cursor.execute(\"SELECT frase FROM faq_questions\")\n",
    "frasi = list(cursor.fetchall())\n",
    "for frase in frasi:\n",
    "    tokens = set()\n",
    "    doc = nlp(frase)\n",
    "    for t in doc:\n",
    "        if t not in tokens:\n",
    "            tokens.add(t)\n",
    "            if t.ent_type_ != \"\" or t.dep_ == \"ROOT\":\n",
    "                sinonimi = set()\n",
    "                nome = t.text\n",
    "                sinonimi.add(nome)\n",
    "                it_lemmas = wn.lemmas(nome.lower(), lang=\"ita\")\n",
    "                for i in range(len(it_lemmas)):\n",
    "                    hypernyms = it_lemmas[i].synset().hypernyms()\n",
    "                    for i in range(len(hypernyms)):\n",
    "                        syn = hypernyms[i].lemmas(lang=\"ita\")\n",
    "                        for s in syn:\n",
    "                            sinonimi.add(str(s).split(\".\")[3].replace(\"')\", \"\"))\n",
    "\n",
    "            if len(sinonimi) > 1:\n",
    "                cursor.execute(\"INSERT INTO synonyms (words) VALUES (\\\"\" + str(sinonimi).replace(\"\\\"\", \"'\") + \"\\\")\")\n",
    "                conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b', 'c'}\n",
      "{'b', 'a', 'd', 'c'}\n"
     ]
    }
   ],
   "source": [
    "# PROBLEMA NELLE RICERCHE: una parola può trovarsi in più array dei sinonimi\n",
    "# POSSIBILE SOLUZIONE: unire i set che hanno almeno un elemento nell'intersezione\n",
    "\n",
    "a = {'a', 'b', 'c'}\n",
    "b = {'b', 'c', 'd'}\n",
    "print(a & b) #intersezione di set\n",
    "a.update(b) #unione di set\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
