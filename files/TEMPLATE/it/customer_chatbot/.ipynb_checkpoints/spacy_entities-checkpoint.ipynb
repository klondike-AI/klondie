{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package omw is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import MySQLdb\n",
    "import re\n",
    "\n",
    "file_connessione = open(\"../db_connections/DB_CONNECTIONS.json\", \"r\")\n",
    "dati_connessione = str(file_connessione.read().replace(':', '=').replace('username', 'user').replace('password=', 'passwd=').replace('database', 'db')[1:-1])\n",
    "conn = eval(\"MySQLdb.connect(\" + dati_connessione + \")\")\n",
    "file_connessione.close()\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT id, frase FROM faq_questions\")\n",
    "questions = list(cursor.fetchall())\n",
    "\n",
    "# Aggiunge colonna entities alla tabella \"faq_questions_1\"\n",
    "#cursor.execute(\"ALTER TABLE faq_questions_1 ADD entities TEXT\")\n",
    "#conn.commit()\n",
    "# Aggiunge la tabella per i sinonimi\n",
    "#cursor.execute(\"\"\"CREATE TABLE synonyms(\n",
    "#id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "#word TEXT,\n",
    "#synonymous TEXT)\n",
    "#\"\"\")\n",
    "#conn.commit()\n",
    "# tabella per riportare le conversazioni di fallback\n",
    "#cursor.execute(\"\"\"CREATE TABLE fallback_events(\n",
    "#id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "#last_message TEXT,\n",
    "#last_timestamp TEXT,\n",
    "#events LONGTEXT)\n",
    "#\"\"\")\n",
    "#conn.commit()\n",
    "# tabella con le conversazioni per sapere se il bot ha risolto il problema\n",
    "#cursor.execute(\"\"\"CREATE TABLE conversations(\n",
    "#id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "#messages LONGTEXT,\n",
    "#last_timestamp TEXT,\n",
    "#events LONGTEXT,\n",
    "#result TEXT)\"\"\")\n",
    "#conn.commit()\n",
    "# tabella con le frasi e le entità di spaCy\n",
    "#cursor.execute(\"\"\"CREATE TABLE spacy_sentences(\n",
    "#id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "#frase TEXT,\n",
    "#entities TEXT)\n",
    "#\"\"\")\n",
    "#conn.commit()\n",
    "# tabella con la debug mode a \"true\" o \"false\"\n",
    "#cursor.execute(\"\"\"CREATE TABLE rasa_debug_mode(\n",
    "#id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "#debug TEXT)\n",
    "#\"\"\")\n",
    "#conn.commit()\n",
    "# tabella con i test per il chatbot\n",
    "#cursor.execute(\"\"\"CREATE TABLE rasa_tests(\n",
    "#id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "#sentence TEXT,\n",
    "#result TEXT,\n",
    "#events TEXT,\n",
    "#expected_faq_title TEXT)\n",
    "#\"\"\")\n",
    "#conn.commit()\n",
    "# tabella con i dati dei clienti che hanno richiesto assistenza\n",
    "#cursor.execute(\"\"\"CREATE TABLE rasa_assistenza(\n",
    "#id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "#messages TEXT,\n",
    "#last_timestamp TEXT,\n",
    "#events TEXT,\n",
    "#email TEXT)\n",
    "#\"\"\")\n",
    "#conn.commit()\n",
    "\n",
    "nlp = spacy.load(\"../model/model_NER/model\") # modello spaCy\n",
    "for q in questions:\n",
    "    #json = {\"action\": \"None\", \"entity_type\": \"None\", \"entity\": \"None\"}\n",
    "    json = {\"action\": \"None\", \"entities\": \"None\"}\n",
    "    entities = []\n",
    "    \n",
    "    doc = nlp(q[1].replace(\"'\", \" \"))\n",
    "    found_action = False\n",
    "    root = \"\"\n",
    "    contains_essere = False\n",
    "    for t in doc:\n",
    "        if t.ent_type_ != \"\" and len(t.text) > 1:\n",
    "            #json[\"entity_type\"] = t.ent_type_.lower()\n",
    "            #json[\"entity\"] = t.text.lower()\n",
    "            tipo = t.ent_type_.lower().replace(\"à\", \"a\").replace(\"é\", \"e\").replace(\"è\", \"e\").replace(\"ò\", \"o\").replace(\"ì\", \"i\").replace(\"ù\", \"u\")\n",
    "            tipo = re.sub('[^a-zA-Z]+', '', tipo)\n",
    "            entita = t.text.lower().replace(\"à\", \"a\").replace(\"é\", \"e\").replace(\"è\", \"e\").replace(\"ò\", \"o\").replace(\"ì\", \"i\").replace(\"ù\", \"u\")\n",
    "            entita = re.sub('[^a-zA-Z]+', '', entita)\n",
    "            entities.append(eval(\"{'entity_type': '\" + tipo + \"', 'entity': '\" + entita + \"'}\"))\n",
    "            \n",
    "        if t.dep_ == \"ROOT\":\n",
    "            root = t.lemma_\n",
    "            \n",
    "        # Se la root è un verbo si prende quella\n",
    "        if t.dep_ == \"ROOT\" and (t.pos_ == \"VERB\" or t.pos_ == \"AUX\") and t.lemma_.lower() not in [\"avere\", \"essere\", \"volere\", \"potere\", \"riuscire\", \"fare\", \"piacere\", \"sapere\", \"dovere\", \"interessare\"]:\n",
    "            found_action = True\n",
    "            json[\"action\"] = t.lemma_.lower()\n",
    "        # Se la root non è un verbo ed esiste un verbo, si prende quello\n",
    "        elif (t.pos_ == \"VERB\" or t.pos_ == \"AUX\") and not found_action and (t.lemma_.lower()[-3:] in [\"are\", \"ere\", \"ire\"] or t.lemma_.lower()[-4:] in [\"arre\", \"orre\", \"urre\"]) and t.lemma_.lower() not in [\"avere\", \"essere\", \"volere\", \"potere\", \"riuscire\", \"fare\", \"piacere\", \"sapere\", \"dovere\", \"interessare\"]:\n",
    "            json[\"action\"] = t.lemma_.lower()\n",
    "        \n",
    "        if t.lemma_.lower() == \"essere\":\n",
    "            contains_essere = True\n",
    "\n",
    "    # Se non c'è il verbo, ma c'è il verbo essere prende lui\n",
    "    if contains_essere == True:\n",
    "        root = \"essere\"\n",
    "        \n",
    "    # Se non c'è il verbo, prende la root di spaCy\n",
    "    if json[\"action\"] == \"None\":\n",
    "        azione = root.lower().replace(\"à\", \"a\").replace(\"é\", \"e\").replace(\"è\", \"e\").replace(\"ò\", \"o\").replace(\"ì\", \"i\").replace(\"ù\", \"u\")\n",
    "        azione = re.sub('[^a-zA-Z]+', '', azione)\n",
    "        json[\"action\"] = azione\n",
    "        \n",
    "    if str(entities) != \"[]\":\n",
    "        json[\"entities\"] = str(entities)\n",
    "    \n",
    "    cursor.execute(\"UPDATE faq_questions SET entities = \\\"\" + str(json).replace('\"', \"'\") + \"\\\" WHERE id = \" + str(q[0]))\n",
    "    conn.commit()\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MySQLdb\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"../model/model_NER/model\") # modello spaCy\n",
    "\n",
    "file_connessione = open(\"../db_connections/DB_CONNECTIONS.json\", \"r\")\n",
    "dati_connessione = str(file_connessione.read().replace(':', '=').replace('username', 'user').replace('password=', 'passwd=').replace('database', 'db')[1:-1])\n",
    "conn = eval(\"MySQLdb.connect(\" + dati_connessione + \")\")\n",
    "file_connessione.close()\n",
    "cursor = conn.cursor()\n",
    "\n",
    "stories = \"\"\n",
    "nlu = \"\"\"## intent:intent_saluti\n",
    "- Ciao\n",
    "- Salve\n",
    "- Buongiorno\n",
    "- Buon Pomeriggio\n",
    "- Buonasera\n",
    "- hey\n",
    "- ehilà\n",
    "- hey ciao\n",
    "- Chi sei?\n",
    "\n",
    "## intent:intent_cosa_posso_fare\n",
    "- Cosa posso fare?\n",
    "- Cosa puoi fare?\n",
    "- Cosa sai fare?\n",
    "- cosa fai?\n",
    "- Che cosa posso fare?\n",
    "- Che cosa sai fare?\n",
    "- Quali sono le tue capacità?\\n\\n\"\"\"\n",
    "domain_intent = \"intents:\\n- intent_saluti\\n- intent_azione\\n- intent_info_azione\\n- intent_entitytype_entity\\n- intent_cosa_posso_fare\\n\"\n",
    "domain_actions = \"actions:\\n\"\n",
    "domain_slot = \"slots:\\n\"\n",
    "domain_utter = \"responses:\\n\"\n",
    "domain_form = \"forms:\\n\"\n",
    "\n",
    "cursor.execute(\"SELECT DISTINCT entities FROM faq_questions\")\n",
    "entities = list(cursor.fetchall())\n",
    "nlu_action = \"\"\"## intent:intent_azione\\n\"\"\"\n",
    "nlu_action_set = set()\n",
    "nlu_entities = \"\"\"## intent:intent_entitytype_entity\\n\"\"\"\n",
    "nlu_entities_set = set()\n",
    "nlu_info_action = \"\"\"## intent:intent_info_azione\\n\"\"\"\n",
    "for ent in entities:\n",
    "    e = eval(ent[0].replace(\"'[\", \"\\\"[\").replace(\"]'\", \"]\\\"\"))\n",
    "    if e['action'] not in nlu_action_set and len(e['action']) > 4 and e['action'] != 'None' and e['action'] != \"/\" and (e['action'][-3:] in [\"are\", \"ere\", \"ire\"] or e['action'][-4:] in [\"arre\", \"orre\", \"urre\"]) and e['action'] not in [\"avere\", \"essere\", \"volere\", \"potere\", \"riuscire\", \"fare\", \"piacere\", \"sapere\", \"dovere\", \"interessare\"]:\n",
    "        nlu_action_set.add(e['action'])\n",
    "        nlu_action = nlu_action + \"- \" + str(e['action']) + \"\\n\"\n",
    "        \n",
    "        nlu_info_action = nlu_info_action + \"- Cosa puoi \" + str(e['action']) + \"\\n\\n\"\n",
    "        nlu_info_action = nlu_info_action + \"- Cosa riesci a \" + str(e['action']) + \"\\n\\n\"\n",
    "        nlu_info_action = nlu_info_action + \"- Cosa sei in grado di \" + str(e['action']) + \"\\n\\n\"\n",
    "        nlu_info_action = nlu_info_action + \"- Cosa sei capace di \" + str(e['action']) + \"\\n\\n\"\n",
    "        nlu_info_action = nlu_info_action + \"- Cosa posso \" + str(e['action']) + \"\\n\\n\"\n",
    "        \n",
    "        cursor.execute(\"SELECT words FROM synonyms WHERE words LIKE \\\"%'\" + e['action'] + \"'%\\\"\")\n",
    "        words = cursor.fetchall()\n",
    "        if len(words) != 0:\n",
    "            sinonimi = eval(words[0][0])\n",
    "            for s in sinonimi:\n",
    "                if e['action'] != s:\n",
    "                    nlu_action_set.add(s)\n",
    "                    nlu_action = nlu_action + \"- \" + str(s) + \"\\n\"\n",
    "                    \n",
    "                    nlu_info_action = nlu_info_action + \"- Cosa puoi \" + str(s) + \"\\n\\n\"\n",
    "                    nlu_info_action = nlu_info_action + \"- Cosa riesci a \" + str(s) + \"\\n\\n\"\n",
    "                    nlu_info_action = nlu_info_action + \"- Cosa sei in grado di \" + str(s) + \"\\n\\n\"\n",
    "                    nlu_info_action = nlu_info_action + \"- Cosa sei capace di \" + str(s) + \"\\n\\n\"\n",
    "                    nlu_info_action = nlu_info_action + \"- Cosa posso \" + str(s) + \"\\n\\n\"\n",
    "\n",
    "    entities = eval(e[\"entities\"])\n",
    "    if entities is not None:\n",
    "        for e1 in entities: # scorro i dizionari\n",
    "            if e1['entity_type'] not in nlu_entities_set and len(e1['entity_type']) != 0 and e1['entity_type'] != \"/\":\n",
    "                nlu_entities_set.add(e1['entity_type'])\n",
    "                nlu_entities = nlu_entities + \"- \" + str(e1['entity_type']) + \"\\n\"\n",
    "            cursor.execute(\"SELECT words FROM synonyms WHERE words LIKE \\\"%'\" + e1['entity'] + \"'%\\\"\")\n",
    "            words = cursor.fetchall()\n",
    "            if len(words) != 0:\n",
    "                sinonimi = eval(words[0][0])\n",
    "                for s in sinonimi:\n",
    "                    if s not in nlu_entities_set and len(e1['entity']) != 0 and e1['entity'] != 'None' and e1['entity'] != \"/\":\n",
    "                        nlu_entities_set.add(s)\n",
    "                        nlu_entities = nlu_entities + \"- \" + str(s) + \"\\n\"\n",
    "            else:\n",
    "                if e1['entity'] not in nlu_entities_set and len(e1['entity']) != 0 and e1['entity'] != \"/\":\n",
    "                    nlu_entities_set.add(e1['entity'])\n",
    "                    nlu_entities = nlu_entities + \"- \" + str(e1['entity']) + \"\\n\"\n",
    "                \n",
    "nlu = nlu + nlu_action + nlu_entities + nlu_info_action\n",
    "\n",
    "\n",
    "\n",
    "stories = stories + \"\"\"## only_action\n",
    "* intent_azione\n",
    "  - action_set_action_only_action\n",
    "  - action_retrieve_types_only_action\n",
    "  - type_form\n",
    "  - form{\"name\": \"type_form\"}\n",
    "  - form{\"name\": null}\n",
    "> check_types_only_action\n",
    "\n",
    "## type_name_empty_only_action\n",
    "> check_types_only_action\n",
    "  - action_retrieve_name_only_action\n",
    "  - slot{\"found_name\":\"false\"}\n",
    "  - name_form\n",
    "  - form{\"name\": \"name_form\"}\n",
    "  - form{\"name\": null}\n",
    "  - action_retrieve_faq_only_action\n",
    "  - slot{\"assertion\": null}\n",
    "> check_check_another_faq_only_action\n",
    "\n",
    "## type_name_chosen_only_action\n",
    "> check_types_only_action\n",
    "  - action_retrieve_name_only_action\n",
    "  - slot{\"found_name\":\"true\"}\n",
    "  - action_retrieve_faq_only_action\n",
    "  - slot{\"assertion\": null}\n",
    "> check_check_another_faq_only_action\n",
    "\n",
    "## check_another_faq_only_action\n",
    "> check_check_another_faq_only_action\n",
    "  - slot{\"check_another_faq\":\"si\"}\n",
    "> check_new_faq_only_action\n",
    "\n",
    "## new_faq_ok_only_action\n",
    "> check_new_faq_only_action\n",
    "  - assertion_form\n",
    "  - form{\"name\": \"assertion_form\"}\n",
    "  - form{\"name\": null}\n",
    "  - slot{\"assertion\":\"si\"}\n",
    "  - action_retrieve_faq_only_action\n",
    "  - slot{\"assertion\": null}\n",
    "> check_problema_risolto\n",
    "  \n",
    "## new_faq_not_ok_only_action\n",
    "> check_new_faq_only_action\n",
    "  - assertion_form\n",
    "  - form{\"name\": \"assertion_form\"}\n",
    "  - form{\"name\": null}\n",
    "  - slot{\"assertion\":\"no\"}\n",
    "  - action_exit\n",
    "  - slot{\"assertion\": null}\n",
    "  - slot{\"check_another_faq\": \"no\"}\n",
    "  - slot{\"found_name\": false}\n",
    "\n",
    "## no_check_another_faq_only_action\n",
    "> check_check_another_faq_only_action\n",
    "  - slot{\"check_another_faq\":\"no\"}\n",
    "> check_problema_risolto\n",
    "\n",
    "\n",
    "\n",
    "## only_entitytype\n",
    "* intent_entitytype_entity\n",
    "  - action_set_action_type_only_action\n",
    "  - action_retrieve_name_only_action\n",
    "  - slot{\"found_name\":\"false\"}\n",
    "  - name_form\n",
    "  - form{\"name\": \"name_form\"}\n",
    "  - form{\"name\": null}\n",
    "  - action_retrieve_action_only_action\n",
    "  - action_form\n",
    "  - form{\"name\": \"action_form\"}\n",
    "  - form{\"name\": null}\n",
    "  - action_retrieve_faq_only_action\n",
    "  - slot{\"assertion\": null}\n",
    "> check_check_another_faq_only_action\n",
    "\n",
    "## only_entity\n",
    "* intent_entitytype_entity\n",
    "  - action_set_action_type_only_action\n",
    "  - action_retrieve_name_only_action\n",
    "  - slot{\"found_name\":\"true\"}\n",
    "  - action_retrieve_action_only_action\n",
    "  - action_form\n",
    "  - form{\"name\": \"action_form\"}\n",
    "  - form{\"name\": null}\n",
    "  - action_retrieve_faq_only_action\n",
    "  - slot{\"assertion\": null}\n",
    "> check_check_another_faq_only_action\n",
    "\n",
    "\n",
    "\n",
    "## problema_risolto_si\n",
    "> check_problema_risolto\n",
    "  - utter_problema_risolto\n",
    "  - assertion_form\n",
    "  - form{\"name\": \"assertion_form\"}\n",
    "  - form{\"name\": null}\n",
    "  - slot{\"assertion\": \"si\"}\n",
    "  - action_exit\n",
    "  - slot{\"assertion\": null}\n",
    "  - slot{\"check_another_faq\": \"no\"}\n",
    "  - slot{\"found_name\": false}\n",
    "\n",
    "## problema_risolto_no\n",
    "> check_problema_risolto\n",
    "  - utter_problema_risolto\n",
    "  - assertion_form\n",
    "  - form{\"name\": \"assertion_form\"}\n",
    "  - form{\"name\": null}\n",
    "  - slot{\"assertion\": \"no\"}\n",
    "  - action_exit\n",
    "  - slot{\"assertion\": null}\n",
    "  - slot{\"check_another_faq\": \"no\"}\n",
    "  - slot{\"found_name\": false}\n",
    "\\n\\n\\n\"\"\"\n",
    "\n",
    "domain_actions = domain_actions + \"\"\"- action_retrieve_types_only_action\n",
    "- action_set_action_only_action\n",
    "- action_set_action_type_only_action\n",
    "- action_retrieve_name_only_action\n",
    "- action_retrieve_faq_only_action\n",
    "- action_retrieve_action_only_action\\n\"\"\"\n",
    "\n",
    "\n",
    "cursor.execute(\"SELECT DISTINCT faq_title FROM faq_questions\")\n",
    "faq_titles = list(cursor.fetchall())\n",
    "\n",
    "for f in faq_titles:\n",
    "    cursor.execute(\"SELECT frase, faq_title, entities FROM faq_questions WHERE faq_title = \\\"\" + f[0] + \"\\\" LIMIT 1\")\n",
    "    question_list = list(cursor.fetchall())\n",
    "    faq_title = question_list[0][1].lower()\n",
    "    \n",
    "    entities = []\n",
    "    azione = eval(question_list[0][2].replace(\"'[\", \"\\\"[\").replace(\"]'\", \"]\\\"\"))[\"action\"]\n",
    "    #################################################################\n",
    "    for i in question_list:\n",
    "        entita = eval(eval(i[2].replace(\"'[\", \"\\\"[\").replace(\"]'\", \"]\\\"\"))[\"entities\"])\n",
    "        if entita is not None:\n",
    "            for ent in entita:\n",
    "                if ent not in entities:\n",
    "                    entities.append(ent)\n",
    "    #################################################################\n",
    "    if str(entities) != \"[]\":\n",
    "        entities = {\"action\": azione, \"entities\": str(entities)}\n",
    "    else:\n",
    "        entities = {\"action\": azione, \"entities\": \"None\"}\n",
    "    \n",
    "    if entities[\"entities\"] != \"None\":\n",
    "        #entity = eval(entities[\"entities\"][0]) # qui c'è il dizionario della prima entità per i nomi degli intenti\n",
    "        \n",
    "        azione_entita_tipo = entities[\"action\"]\n",
    "        primo_tipo = \"\"\n",
    "        for entity in eval(entities[\"entities\"]):\n",
    "            if primo_tipo == \"\":\n",
    "                primo_tipo = entity[\"entity_type\"]\n",
    "            azione_entita_tipo = azione_entita_tipo + \"\"\"_\"\"\" + entity[\"entity_type\"] + \"\"\"_\"\"\" + entity[\"entity\"]\n",
    "            \n",
    "        ### Manca il type dell'entità\n",
    "        stories = stories + \"\"\"## \"\"\" + azione_entita_tipo + \"\"\"_type_empty\n",
    "* intent_\"\"\" + faq_title + \"\"\"_\"\"\" + azione_entita_tipo + \"\"\"_type_empty\n",
    "  - action_set_action\n",
    "  - slot{\"action_1\": \\\"\"\"\" + entities[\"action\"] + \"\"\"\\\"}\n",
    "  - slot{\"type_1\":\"null\"}\n",
    "  - action_retrieve_types\n",
    "  - type_form\n",
    "  - form{\"name\": \"type_form\"}\n",
    "  - form{\"name\": null}\n",
    "> check_types_\"\"\" + faq_title + \"\"\"_\"\"\" + azione_entita_tipo + \"\"\"\n",
    "\n",
    "## \"\"\" + azione_entita_tipo + \"\"\"_type_chosen\n",
    "> check_types_\"\"\" + faq_title + \"\"\"_\"\"\" + azione_entita_tipo + \"\"\"\n",
    "  - action_retrieve_name\n",
    "  - slot{\"found_name\":\"false\"}\n",
    "  - name_form\n",
    "  - form{\"name\": \"name_form\"}\n",
    "  - form{\"name\": null}\n",
    "  - action_retrieve_faq\n",
    "  - slot{\"assertion\": null}\n",
    "> check_check_another_faq\n",
    "  \n",
    "## \"\"\" + azione_entita_tipo + \"\"\"_type_name_chosen\n",
    "> check_types_\"\"\" + faq_title + \"\"\"_\"\"\" + azione_entita_tipo + \"\"\"\n",
    "  - action_retrieve_name\n",
    "  - slot{\"found_name\":\"true\"}\n",
    "  - action_retrieve_faq\n",
    "  - slot{\"assertion\": null}\n",
    "> check_check_another_faq\\n\\n\"\"\"\n",
    "\n",
    "\n",
    "        ### Manca solo il nome dell'entità\n",
    "        stories = stories + \"\"\"## \"\"\" + azione_entita_tipo + \"\"\"_name_empty\n",
    "* intent_\"\"\" + faq_title + \"\"\"_\"\"\" + azione_entita_tipo + \"\"\"_name_empty\n",
    "  - action_set_action_type\n",
    "  - slot{\"action_1\": \\\"\"\"\" + entities[\"action\"] + \"\"\"\\\"}\n",
    "  - slot{\"type_1\": \\\"\"\"\" + primo_tipo + \"\"\"\\\"}\n",
    "  - slot{\"name_1\":\"null\"}\n",
    "  - action_retrieve_name\n",
    "  - name_form\n",
    "  - form{\"name\": \"name_form\"}\n",
    "  - form{\"name\": null}\n",
    "> check_types_\"\"\" + faq_title + \"\"\"_\"\"\" + azione_entita_tipo + \"\"\"\n",
    "\"\"\"\n",
    "    \n",
    "    stories = stories + \"\"\"\\n## \"\"\" + faq_title + \"\"\"\n",
    "* \"\"\" + faq_title + \"\"\"\n",
    "  - action_spacy\n",
    "  - action_check_print_action\n",
    "  - action_form\n",
    "  - form{\"name\": \"action_form\"}\n",
    "  - form{\"name\": null}\n",
    "  - action_check_print_name\n",
    "  - name_form\n",
    "  - form{\"name\": \"name_form\"}\n",
    "  - form{\"name\": null}\n",
    "  - action_check_another_faq\n",
    "> check_assertion_another_faq\\n\\n\"\"\"\n",
    "    \n",
    "    stories = stories + \"\"\"\\n## \"\"\" + faq_title + \"\"\"_si\n",
    "> check_assertion_another_faq\n",
    "  - slot{\"assertion\": null}\n",
    "  - assertion_form\n",
    "  - form{\"name\": \"assertion_form\"}\n",
    "  - form{\"name\": null}\n",
    "  - slot{\"assertion\": \"si\"}\n",
    "  - action_answer\n",
    "  - slot{\"name_1\": null}\n",
    "  - slot{\"type_1\": null}\n",
    "  - slot{\"action_1\": null}\n",
    "  - slot{\"assertion\": null}\n",
    "> check_problema_risolto\\n\\n\"\"\"\n",
    "                               \n",
    "    stories = stories + \"\"\"\\n## \"\"\" + faq_title + \"\"\"_no\n",
    "> check_assertion_another_faq\n",
    "  - slot{\"assertion\": null}\n",
    "  - assertion_form\n",
    "  - form{\"name\": \"assertion_form\"}\n",
    "  - form{\"name\": null}\n",
    "  - slot{\"assertion\": \"no\"}\n",
    "  - action_exit\n",
    "  - slot{\"assertion\": null}\n",
    "  - slot{\"check_another_faq\": \"no\"}\n",
    "  - slot{\"found_name\": false}\\n\\n\"\"\"\n",
    "                               \n",
    "    stories = stories + \"\"\"\\n## \"\"\" + faq_title + \"\"\"_assertion\n",
    "> check_assertion_another_faq\n",
    "  - slot{\"assertion\":\"si\"}\n",
    "  - action_exit\n",
    "  - slot{\"assertion\": null}\n",
    "  - slot{\"check_another_faq\": \"no\"}\n",
    "  - slot{\"found_name\": false}\n",
    "> check_problema_risolto\\n\\n\"\"\"\n",
    "    \n",
    "    cursor.execute(\"SELECT frase, faq_title, entities FROM faq_questions WHERE faq_title = \\\"\" + faq_title + \"\\\"\")\n",
    "    quests = list(cursor.fetchall())\n",
    "    nlu = nlu + \"## intent:\" + faq_title + \"\\n\"\n",
    "    \n",
    "    nlu_name_empty = \"\"\n",
    "    nlu_type_empty = \"\"\n",
    "    if entities[\"entities\"] != \"None\":\n",
    "        #entity = eval(entities[\"entities\"][0]) # qui c'è il dizionario della prima entità per i nomi degli intenti\n",
    "        nlu_name_empty = nlu_name_empty + \"## intent:intent_\" + faq_title + \"\"\"_\"\"\" + entities[\"action\"] \n",
    "        nlu_type_empty = nlu_type_empty + \"## intent:intent_\" + faq_title + \"\"\"_\"\"\" + entities[\"action\"]\n",
    "        for entity in eval(entities[\"entities\"]):\n",
    "            nlu_name_empty = nlu_name_empty + \"_\" + entity[\"entity_type\"] + \"_\" + entity[\"entity\"]\n",
    "            nlu_type_empty = nlu_type_empty + \"_\" + entity[\"entity_type\"] + \"_\" + entity[\"entity\"]\n",
    "        nlu_name_empty = nlu_name_empty + \"_name_empty\\n\"\n",
    "        nlu_type_empty = nlu_type_empty + \"_type_empty\\n\"\n",
    "        \n",
    "    for q1 in quests:\n",
    "        nlu = nlu + \"- \" + q1[0].replace(\"_\", \"\").lower() + \"\\n\"\n",
    "        if q1[1].lower() != \"none\":\n",
    "            this_faq_title = \"- \" + q1[1].replace(\"_\", \" \").lower() + \"\\n\"\n",
    "            if this_faq_title not in nlu:\n",
    "                nlu = nlu + this_faq_title\n",
    "                nlu = nlu + \"- voglio \" + q1[1].replace(\"_\", \" \").lower() + \"\\n\"\n",
    "                nlu = nlu + \"- come faccio a \" + q1[1].replace(\"_\", \" \").lower() + \"\\n\"\n",
    "        \n",
    "        ### Questo pezzo di codice lo faccio per ogni entita' cosi' da avere più frasi in nlu\n",
    "        if eval(eval(q1[2].replace(\"'[\", \"\\\"[\").replace(\"]'\", \"]\\\"\"))['entities']) is not None:\n",
    "            for entity in eval(eval(q1[2].replace(\"'[\", \"\\\"[\").replace(\"]'\", \"]\\\"\"))['entities']):\n",
    "                if eval(q1[2].replace(\"'[\", \"\\\"[\").replace(\"]'\", \"]\\\"\"))['action'].lower() != \"none\" and entity['entity'].lower() != \"none\":\n",
    "                    this_entities = eval(q1[2].replace(\"'[\", \"\\\"[\").replace(\"]'\", \"]\\\"\"))['action'] + \" \" + entity['entity']\n",
    "                    this_faq_entity = \"- \" + this_entities.replace(\"_\", \"\").lower() + \"\\n\"\n",
    "                    if this_faq_entity not in nlu and \"essere\" not in this_faq_entity:\n",
    "                        nlu = nlu + this_faq_entity\n",
    "                        nlu = nlu + \"- voglio \" + this_entities.replace(\"_\", \"\").lower() + \"\\n\"\n",
    "                        nlu = nlu + \"- come faccio a \" + this_entities.replace(\"_\", \"\").lower() + \"\\n\"\n",
    "\n",
    "                q_lemma = nlp(eval(q1[2].replace(\"'[\", \"\\\"[\").replace(\"]'\", \"]\\\"\"))['action'].lower())[0].lemma_ # lemma\n",
    "                cursor.execute(\"SELECT words FROM synonyms WHERE words LIKE \\\"%'\" + q_lemma + \"'%\\\" OR words LIKE \\\"%'\" + eval(q1[2].replace(\"'[\", \"\\\"[\").replace(\"]'\", \"]\\\"\"))['action'].lower() + \"'%\\\"\")\n",
    "                words = cursor.fetchall()\n",
    "                if len(words) != 0:\n",
    "                    sinonimi = eval(words[0][0])\n",
    "                    if q_lemma in sinonimi or eval(q1[2].replace(\"'[\", \"\\\"[\").replace(\"]'\", \"]\\\"\"))['action'].lower() in sinonimi:\n",
    "                        for s in sinonimi: # lemma\n",
    "                            this_entities = s.lower() + \" \" + entity['entity']\n",
    "                            this_faq_entity = \"- \" + this_entities.replace(\"_\", \"\").lower() + \"\\n\"\n",
    "                            if this_faq_entity not in nlu:\n",
    "                                nlu = nlu + this_faq_entity\n",
    "                                nlu = nlu + \"- voglio \" + this_entities.replace(\"_\", \"\").lower() + \"\\n\"\n",
    "                                nlu = nlu + \"- come faccio a \" + this_entities.replace(\"_\", \"\").lower() + \"\\n\"\n",
    "\n",
    "        # sinonimi\n",
    "        trova_sinonimi(\"\", q1[0].replace(\"_\", \"\").lower())\n",
    "        \n",
    "        if entities[\"entities\"] != \"None\":\n",
    "            name_empty = q1[0].replace(\"_\", \"\").lower()\n",
    "            type_empty = q1[0].replace(\"_\", \"\").lower()\n",
    "            for entity in eval(entities[\"entities\"]):\n",
    "                name_empty = replace_word(name_empty, entity[\"entity\"], entity[\"entity_type\"]) + '\\n'\n",
    "                #name_empty = name_empty.replace(entity[\"entity\"], entity[\"entity_type\"]) + \"\\n\"\n",
    "                type_empty = replace_word(type_empty, entity[\"entity\"], entity[\"entity_type\"])\n",
    "                type_empty = replace_word(type_empty, entity[\"entity_type\"], \"\") + '\\n'\n",
    "                #type_empty = type_empty.replace(\"_\", \"\").lower().replace(entity[\"entity\"], entity[\"entity_type\"]).replace(entity[\"entity_type\"], \"\") + \"\\n\"\n",
    "                # sinonimi\n",
    "                trova_sinonimi_entita(\"\", q1[0].replace(\"_\", \"\").lower(), entities[\"entities\"])\n",
    "            nlu_name_empty = nlu_name_empty + \"- \" + name_empty\n",
    "            nlu_type_empty = nlu_type_empty + \"- \" + type_empty\n",
    "            \n",
    "    if entities[\"entities\"] != \"None\":\n",
    "        nlu = nlu + nlu_name_empty + nlu_type_empty\n",
    "\n",
    "    cursor.execute(\"SELECT frase FROM faq_answers WHERE faq_title = \\\"\" + faq_title + \"\\\"\")\n",
    "    response = cursor.fetchall()[0][0]\n",
    "    domain_utter = domain_utter + \"  utter_\" + faq_title + \":\\n  - text: \" + response + \"\\n\"\n",
    "    \n",
    "    if entities[\"entities\"] != \"None\":        \n",
    "        domain_intent = domain_intent + \"\"\"- \"\"\" + faq_title + \"\"\"\\n- intent_\"\"\" + faq_title + \"\"\"_\"\"\" + entities[\"action\"]\n",
    "        for entity in eval(entities[\"entities\"]):\n",
    "            domain_intent = domain_intent + \"\"\"_\"\"\" + entity[\"entity_type\"] + \"\"\"_\"\"\" + entity[\"entity\"]\n",
    "        domain_intent = domain_intent + \"_type_empty\\n- intent_\" + faq_title + \"\"\"_\"\"\" + entities[\"action\"]\n",
    "        for entity in eval(entities[\"entities\"]):\n",
    "            domain_intent = domain_intent + \"_\" + entity[\"entity_type\"] + \"\"\"_\"\"\" + entity[\"entity\"] \n",
    "        domain_intent = domain_intent + \"\"\"_name_empty\\n\"\"\"\n",
    "    else:\n",
    "        domain_intent = domain_intent + \"\"\"- \"\"\" + faq_title + \"\"\"\\n\"\"\"\n",
    "        \n",
    "domain_intent = domain_intent.replace(\"/\", \"\")\n",
    "stories = stories + \"\"\"## check_another_faq\n",
    "> check_check_another_faq\n",
    "  - slot{\"check_another_faq\":\"si\"}\n",
    "> check_new_faq\n",
    "\n",
    "## new_faq_ok\n",
    "> check_new_faq\n",
    "  - assertion_form\n",
    "  - form{\"name\": \"assertion_form\"}\n",
    "  - form{\"name\": null}\n",
    "  - slot{\"assertion\":\"si\"}\n",
    "  - action_retrieve_faq\n",
    "  - slot{\"assertion\": null}\n",
    "> check_problema_risolto\n",
    "  \n",
    "## new_faq_not_ok\n",
    "> check_new_faq\n",
    "  - assertion_form\n",
    "  - form{\"name\": \"assertion_form\"}\n",
    "  - form{\"name\": null}\n",
    "  - slot{\"assertion\":\"no\"}\n",
    "  - action_exit\n",
    "  - slot{\"assertion\": null}\n",
    "  - slot{\"check_another_faq\": \"no\"}\n",
    "  - slot{\"found_name\": false}\n",
    "\n",
    "## no_check_another_faq\n",
    "> check_check_another_faq\n",
    "  - slot{\"check_another_faq\":\"no\"}\n",
    "> check_problema_risolto\n",
    "  \n",
    "## saluti\n",
    "* intent_saluti\n",
    "  - utter_saluti\n",
    "  \n",
    "## cosa_posso_fare\n",
    "* intent_cosa_posso_fare\n",
    "  - utter_cosa_posso_fare\n",
    "  - utter_come_posso_aiutarti\n",
    "\n",
    "## info_azioni\n",
    "* intent_info_azione\n",
    "  - action_info_azione\\n\\n\"\"\"\n",
    "\n",
    "domain_form = domain_form + \"\"\"- type_form\n",
    "- name_form\n",
    "- assertion_form\n",
    "- action_form\\n\"\"\"\n",
    "\n",
    "domain_actions = domain_actions + \"\"\"- action_retrieve_types\n",
    "- action_set_action\n",
    "- action_set_action_type\n",
    "- action_retrieve_name\n",
    "- action_retrieve_faq\n",
    "- action_exit\n",
    "- action_spacy\n",
    "- action_check_print_action\n",
    "- action_check_print_name\n",
    "- action_check_another_faq\n",
    "- action_answer\n",
    "- action_custom_fallback\n",
    "- action_info_azione\\n\"\"\" # - action_check_print_type ... per ora abbiamo deciso di non usarla\n",
    "\n",
    "domain_slot = domain_slot + \"\"\"  'type_1':\n",
    "    auto_fill: false\n",
    "    type: unfeaturized\n",
    "  'name_1':\n",
    "    auto_fill: false\n",
    "    type: unfeaturized\n",
    "  'action_1':\n",
    "    auto_fill: false\n",
    "    type: unfeaturized\n",
    "  'found_name':\n",
    "    initial_value: 'false'\n",
    "    type: categorical\n",
    "    values:\n",
    "    - 'true'\n",
    "    - 'false'\n",
    "    - __other__\n",
    "  'assertion':\n",
    "    type: categorical\n",
    "    values:\n",
    "    - 'si'\n",
    "    - 'no'\n",
    "    - __other__\n",
    "  'check_another_faq':\n",
    "    initial_value: 'no'\n",
    "    type: categorical\n",
    "    values:\n",
    "    - 'si'\n",
    "    - 'no'\n",
    "    - __other__\\n\\n\"\"\"\n",
    "\n",
    "nlu = nlu.replace(\"- \\n\", \"\")\n",
    "nlu_temp = \"\"\n",
    "for n in nlu.split(\"\\n\"):\n",
    "    if (n + \"\\n\") not in nlu_temp:\n",
    "        nlu_temp = nlu_temp + n + \"\\n\"\n",
    "nlu = nlu_temp\n",
    "\n",
    "\"\"\"\n",
    "######################################################################\n",
    "##### Aggiunta dei sinonimi per gli intenti con meno di 10 frasi #####\n",
    "######################################################################\n",
    "# estrazione dei nomi degli intenti\n",
    "nlp_sin = spacy.load(\"it_core_news_lg\") # per verificare la similarita' dei sinonimi\n",
    "\n",
    "intenti = nlu.split('##')\n",
    "intenti.remove('')\n",
    "i = 0\n",
    "for intent in intenti:\n",
    "    intenti[i] = intent.split('\\n')[0].strip()\n",
    "    i = i + 1\n",
    "\n",
    "# estrazione delle frasi\n",
    "nlu_split = re.split('##.*\\n', nlu)\n",
    "nlu_split.remove('')\n",
    "intent_ct = 0\n",
    "new_nlu = \"\"\n",
    "\n",
    "# gestione di ogni singolo intento con le sue n frasi\n",
    "for n in nlu_split:\n",
    "    nlu_sentences = n.split('- ')\n",
    "    nlu_sentences.remove('')\n",
    "    n_frasi = len(nlu_sentences)\n",
    "    \n",
    "    i = 0\n",
    "    stop_search = False\n",
    "    new_s = n + '\\n'\n",
    "    \n",
    "    #si scorrono tutte le frasi di un intento\n",
    "    for s in nlu_sentences:\n",
    "        #new_s = new_s + \"- \" + s + '\\n'\n",
    "        if stop_search or intent_ct < 4 or n_frasi > 9:\n",
    "            break\n",
    "            \n",
    "        # per ogni parola si cercano sinonimi fino a che non si arriva a 10 frasi diverse\n",
    "        for w in s.split():\n",
    "            if stop_search: # se è True, abbiamo 10 frasi\n",
    "                break\n",
    "            \n",
    "            nome = ''.join(x for x in w if x.isalpha()).lower()\n",
    "            \n",
    "            sinonimi = set()\n",
    "            it_lemmas = wn.lemmas(nome.lower(), lang=\"ita\")\n",
    "            for i in range(len(it_lemmas)):\n",
    "                hypernyms = it_lemmas[i].synset().hypernyms()\n",
    "                for i in range(len(hypernyms)):\n",
    "                    syn = hypernyms[i].lemmas(lang=\"ita\")\n",
    "                    for s1 in syn:\n",
    "                        sinonimi.add(str(s1).split(\".\")[3].replace(\"')\", \"\"))\n",
    "            if nome in sinonimi:\n",
    "                sinonimi.remove(nome)\n",
    "            \n",
    "            for sin in sinonimi:\n",
    "                if n_frasi > 9 or intent_ct < 4:\n",
    "                    stop_search = True\n",
    "                    break\n",
    "                ##### Verifica con spaCy se le parole sono abbastanza simili\n",
    "                if nlp_sin(sin).similarity(nlp_sin(nome)) > 0.6:\n",
    "                    new_sin_sentence = replace_word(s, w, sin.replace(\"_\", \" \"))\n",
    "                    new_s = new_s + \"- \" + new_sin_sentence + '\\n'\n",
    "                    n_frasi = n_frasi + 1\n",
    "        i = i + 1\n",
    "    \n",
    "    new_nlu = new_nlu + '## ' + intenti[intent_ct] + \"\\n\" + new_s.replace('\\n\\n', '\\n')\n",
    "    intent_ct = intent_ct + 1\n",
    "f = open(\"./rasa-assistant/data/nlu.md\", \"w\")\n",
    "new_nlu = re.sub(' +', ' ', new_nlu)\n",
    "f.write(new_nlu.replace(\"/\", \"\"))\n",
    "f.close()\n",
    "######################################################################\n",
    "\"\"\"\n",
    "\n",
    "f = open(\"./rasa-assistant/data/nlu.md\", \"w\")\n",
    "nlu = re.sub(' +', ' ', nlu)\n",
    "f.write(nlu.replace(\"/\", \"\"))\n",
    "f.close()\n",
    "\n",
    "f = open(\"./rasa-assistant/data/stories.md\", \"w\")\n",
    "f.write(stories.replace(\"/\", \"\"))\n",
    "f.close()\n",
    "\n",
    "domain_utter = domain_utter + \"\"\"  utter_come_posso_aiutarti:\\n  - text: Come posso aiutarti?\n",
    "  utter_saluti:\\n  - text: Ciao, sono il bot di vtenext! Come posso aiutarti?\n",
    "  utter_problema_risolto:\\n  - text: Sono riuscito a risolvere il tuo problema?\n",
    "  utter_cosa_posso_fare:\\n  - text: Posso rispondere alle tue domande. In particolare posso aiutarti a \"\"\"\n",
    "for a in nlu_action_set:\n",
    "    domain_utter = domain_utter + a + \", \"\n",
    "domain_utter = domain_utter[:-2] +\"\\n\\n\"\n",
    "domain = domain_intent + domain_actions + domain_slot + domain_utter + domain_form + \"\"\"\n",
    "session_config:\n",
    "  carry_over_slots_to_new_session: true\n",
    "  session_expiration_time: 0\"\"\"\n",
    "f = open(\"./rasa-assistant/domain.yml\", \"w\")\n",
    "f.write(domain.replace(\"#\", \"\"))\n",
    "f.close()\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rimpiazza \"findWord\" con \"replaceWord\" in \"text\", ma non le parole che contengono \"findWord\"\n",
    "def replace_word(text, findWord, replaceWord):\n",
    "    return ' '.join(replaceWord if word == findWord else word for word in text.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trova_sinonimi(q0, q1):\n",
    "    global nlu\n",
    "    global nlp\n",
    "    for q in q1.split(\" \"):\n",
    "        if len(q) == 0:\n",
    "            continue\n",
    "        q_lemma = nlp(q.lower())[0].lemma_ # lemma\n",
    "        cursor.execute(\"SELECT words FROM synonyms WHERE words LIKE \\\"%'\" + q_lemma + \"'%\\\" OR words LIKE \\\"%'\" + q + \"'%\\\"\")\n",
    "        words = cursor.fetchall()\n",
    "        if len(words) != 0:\n",
    "            sinonimi = eval(words[0][0])\n",
    "            if q_lemma in sinonimi or q.lower() in sinonimi:\n",
    "                for s in sinonimi:\n",
    "                    if q.lower() != s.lower():\n",
    "                        new_sentence = replace_word(q1, q, s)\n",
    "                        if (\"- \" + q0 + new_sentence + \"\\n\").lower() not in nlu:\n",
    "                            nlu = nlu + \"- \" + q0 + new_sentence + \"\\n\"\n",
    "                        if len(new_sentence.split(s)) > 1:\n",
    "                            trova_sinonimi(q0 + new_sentence.split(s)[0] + s, new_sentence.split(s)[1])\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trova_sinonimi_entita(q0, q1, entities):\n",
    "    global nlu_name_empty\n",
    "    global nlu_type_empty\n",
    "    global nlp\n",
    "    global nlu\n",
    "    for q in q1.split(\" \"):\n",
    "        if len(q) == 0:\n",
    "            continue\n",
    "        q_lemma = nlp(q.lower())[0].lemma_ # lemma\n",
    "        cursor.execute(\"SELECT words FROM synonyms WHERE words LIKE \\\"%'\" + q_lemma + \"'%\\\" OR words LIKE \\\"%'\" + q + \"'%\\\"\")\n",
    "        words = cursor.fetchall()\n",
    "        if len(words) != 0:\n",
    "            sinonimi = eval(words[0][0])\n",
    "            if q_lemma in sinonimi or q.lower() in sinonimi:\n",
    "                for s in sinonimi: # lemma\n",
    "                    all_entita = []\n",
    "                    if str(type(entities)) == \"<class 'str'>\":\n",
    "                        entities = eval(entities)\n",
    "                    for e in entities:\n",
    "                        all_entita.append(e[\"entity\"].lower())\n",
    "                    if q.lower() != s.lower() and q.lower() not in all_entita:\n",
    "                        new_sentence = replace_word(q1, q, s)\n",
    "                        replace_name_empty = new_sentence\n",
    "                        replace_type_empty = new_sentence\n",
    "                        for e in entities:\n",
    "                            replace_name_empty = replace_word(replace_name_empty, e[\"entity\"], e[\"entity_type\"])\n",
    "                            #replace_name_empty = replace_name_empty.replace(e[\"entity\"], e[\"entity_type\"])\n",
    "                            replace_type_empty = replace_word(replace_type_empty, e[\"entity\"], e[\"entity_type\"])\n",
    "                            replace_type_empty = replace_word(replace_type_empty, e[\"entity_type\"], \"\")\n",
    "                            #replace_type_empty = replace_type_empty.replace(e[\"entity\"], e[\"entity_type\"]).replace(e[\"entity_type\"], \"\")\n",
    "                        if (\"- \" + q0 + replace_name_empty + \"\\n\").lower() not in nlu_name_empty and (\"- \" + q0 + replace_name_empty + \"\\n\").lower() not in nlu:\n",
    "                            nlu_name_empty = nlu_name_empty + \"- \" + q0 + replace_name_empty + \"\\n\"\n",
    "                        if (\"- \" + q0 + replace_type_empty + \"\\n\").lower() not in nlu_type_empty and (\"- \" + q0 + replace_type_empty + \"\\n\").lower() not in nlu:\n",
    "                            nlu_type_empty = nlu_type_empty + \"- \" + q0 + replace_type_empty + \"\\n\"\n",
    "                        new_q1 = replace_word(q1, q, s)\n",
    "                        if len(new_q1.split(s)) > 1:\n",
    "                            trova_sinonimi_entita(q0 + new_q1.split(s)[0] + s, new_q1.split(s)[1], entities)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configurare AUX ROOT \n",
      "outlook ADV obj EMAILPROVIDER\n"
     ]
    }
   ],
   "source": [
    "\"\"\"import spacy\n",
    "nlp = spacy.load(\"../model/model_NER/model\") # modello spaCy\n",
    "a = nlp(\"configurare outlook\")\n",
    "for aa in a:\n",
    "    print(aa.text, aa.pos_, aa.dep_,  aa.ent_type_)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utilizzare AUX ROOT \n",
      "outlook365 PROPN punct MISC\n"
     ]
    }
   ],
   "source": [
    "\"\"\"import spacy\n",
    "nlp_fallback = spacy.load(\"it_core_news_lg\") # it_core_news_lg\n",
    "a = nlp_fallback(\"utilizzare outlook365\")\n",
    "for aa in a:\n",
    "    print(aa.text, aa.pos_, aa.dep_, aa.ent_type_)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backup sentences table\n",
    "\n",
    "file_connessione = open(\"../db_connections/DB_CONNECTIONS.json\", \"r\")\n",
    "dati_connessione = str(file_connessione.read().replace(':', '=').replace('username', 'user').replace('password=', 'passwd=').replace('database', 'db')[1:-1])\n",
    "conn = eval(\"MySQLdb.connect(\" + dati_connessione + \")\")\n",
    "file_connessione.close()\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT * FROM sentences\")\n",
    "questions = cursor.fetchall()\n",
    "conn.close()\n",
    "\n",
    "f = open(\"../sentences_backup.txt\", \"w\")\n",
    "f.write(str(questions))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mostra quali intenti non raggiungono il numero minimo di frasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "Attenzione! I seguenti intenti contengono poche frasi (consigliate almeno 10):\n",
      "- link_modulo_traduzioni: 6\n",
      "- link_import_dati: 7\n",
      "- gestionali_integrati: 2\n",
      "- lista_uitypes: 4\n",
      "- sostituire_jqueryattr_jqueryprop: 6\n",
      "- template_google_material: 7\n",
      "- processi_bpmn_bloccati: 6\n",
      "- numero_utenti_oneshot: 2\n",
      "- attivare_adodb_php: 2\n",
      "- nascondere_campi_changelog: 3\n",
      "- plugin_adhoc_revolution_zucchetti: 4\n",
      "- verioni_stabili_vte: 7\n",
      "- significati_valori_colonne: 6\n",
      "- caratteristiche_cloud: 4\n",
      "- funzionamento_componenti_homepage: 2\n",
      "- dump_piu_veloci_mydumper: 7\n",
      "- funzionamento_shark_panel: 3\n",
      "- funzionamento_cron_unificato: 4\n",
      "- documentazione_vte: 2\n"
     ]
    }
   ],
   "source": [
    "file_connessione = open(\"../db_connections/DB_CONNECTIONS.json\", \"r\")\n",
    "dati_connessione = str(file_connessione.read().replace(':', '=').replace('username', 'user').replace('password=', 'passwd=').replace('database', 'db')[1:-1])\n",
    "conn = eval(\"MySQLdb.connect(\" + dati_connessione + \")\")\n",
    "file_connessione.close()\n",
    "cursor = conn.cursor()\n",
    "\n",
    "f = open(\"./rasa-assistant/data/nlu.md\",\"r\")\n",
    "nlu = f.read()\n",
    "f.close()\n",
    "\n",
    "intenti = nlu.split('##')\n",
    "intenti.remove('')\n",
    "i = 0\n",
    "for intent in intenti:\n",
    "    intenti[i] = intent.split('\\n')[0].strip()\n",
    "    i = i + 1\n",
    "\n",
    "# estrazione delle frasi\n",
    "nlu_split = re.split('##.*\\n', nlu)\n",
    "nlu_split.remove('')\n",
    "intent_ct = 0\n",
    "warning_titles = set()\n",
    "warning_faq_title = set()\n",
    "\n",
    "message = \"Attenzione! I seguenti intenti contengono poche frasi (consigliate almeno 10):\"\n",
    "\n",
    "# gestione di ogni singolo intento con le sue n frasi\n",
    "for n in nlu_split:\n",
    "    if intent_ct < 4: # i primi 4 intenti sono quelli di default\n",
    "        intent_ct = intent_ct + 1\n",
    "        continue\n",
    "    nlu_sentences = n.split('- ')\n",
    "    nlu_sentences.remove('')\n",
    "    n_frasi = len(nlu_sentences)\n",
    "    \n",
    "    if n_frasi < 8 and intenti[intent_ct] not in warning_titles: # se abbiamo meno di 10 frasi su intento\n",
    "        warning_titles.add(intenti[intent_ct])\n",
    "        faq_title = intenti[intent_ct].split('intent:')[1]\n",
    "        if faq_title[-5:] == \"empty\": # intento non completo completo\n",
    "            intent = \"_\".join(faq_title.split('_')[1:])\n",
    "            faq_title_question = intent.split(\"_\")[0]\n",
    "            for i in intent.split(\"_\")[1:]:\n",
    "                cursor.execute(\"SELECT faq_title FROM faq_questions WHERE faq_title LIKE '%\" + faq_title_question + \"%' LIMIT 1\")\n",
    "                faq = list(cursor.fetchall())\n",
    "                if len(faq) == 0:\n",
    "                    break\n",
    "                faq_title_question = faq_title_question + \"_\" + i\n",
    "            faq_title = \"_\".join(faq_title_question.split('_')[0:-1])\n",
    "            #faq_title = faq_title.split('_')[1:-5]\n",
    "            #faq_title = \"_\".join(faq_title)\n",
    "        \n",
    "        if faq_title not in warning_faq_title:\n",
    "            warning_faq_title.add(faq_title)\n",
    "            message = message + \"\\n- \" + faq_title + \": \" + str(n_frasi)\n",
    "    intent_ct = intent_ct + 1\n",
    "        \n",
    "if len(warning_titles) > 0:\n",
    "    print(len(warning_titles))\n",
    "    print(message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserimento delle frasi per spaCy nella tabella \"spacy_sentences\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_connessione = open(\"../db_connections/DB_CONNECTIONS.json\", \"r\")\n",
    "dati_connessione = str(file_connessione.read().replace(':', '=').replace('username', 'user').replace('password=', 'passwd=').replace('database', 'db')[1:-1])\n",
    "conn = eval(\"MySQLdb.connect(\" + dati_connessione + \")\")\n",
    "file_connessione.close()\n",
    "cursor = conn.cursor()\n",
    "\n",
    "f = open(\"../model/model_NER/train_ner.txt\", \"r\")\n",
    "train_ner = f.read()\n",
    "f.close()\n",
    "\n",
    "for s in train_ner.split('\\n'):\n",
    "    tupla = eval(s.strip())\n",
    "    frase = tupla[0][0]\n",
    "    print(frase) #frase\n",
    "    entities = tupla[0][1]['entities']\n",
    "    print(entities) #entities\n",
    "    #cursor.execute(\"INSERT INTO spacy_sentences (frase, entities) VALUES (\\\"\" + frase.replace(\"\\\"\", \"'\") + \"\\\", \\\"\"+ str(entities).replace(\"\\\"\", \"'\") + \"\\\")\")\n",
    "    #conn.commit()\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserimento Nuovi Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MySQLdb\n",
    "\n",
    "file_connessione = open(\"../db_connections/DB_CONNECTIONS.json\", \"r\")\n",
    "dati_connessione = str(file_connessione.read().replace(':', '=').replace('username', 'user').replace('password=', 'passwd=').replace('database', 'db')[1:-1])\n",
    "conn = eval(\"MySQLdb.connect(\" + dati_connessione + \")\")\n",
    "file_connessione.close()\n",
    "cursor = conn.cursor()\n",
    "\n",
    "sentence = \"rinnovare vte\\nsi\"\n",
    "expected_faq_title = \"rinnovo_licenza_vte\"\n",
    "\n",
    "cursor.execute(\"INSERT INTO rasa_tests (sentence, expected_faq_title) VALUES (\\\"\" + sentence + \"\\\", \\\"\"+ expected_faq_title + \"\\\")\")\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
